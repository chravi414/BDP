{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import DoubleType,IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Regression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True).option(\"delimiter\", \",\")\\\n",
    ".load(\"imports-85.data\")\n",
    "data = df.withColumnRenamed(\"wheel-base\", \"label\").select(\"label\", \"length\", \"width\", \"height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+------+\n",
      "|label|length|width|height|\n",
      "+-----+------+-----+------+\n",
      "| 88.6| 168.8| 64.1|  48.8|\n",
      "| 88.6| 168.8| 64.1|  48.8|\n",
      "| 94.5| 171.2| 65.5|  52.4|\n",
      "| 99.8| 176.6| 66.2|  54.3|\n",
      "| 99.4| 176.6| 66.4|  54.3|\n",
      "| 99.8| 177.3| 66.3|  53.1|\n",
      "|105.8| 192.7| 71.4|  55.7|\n",
      "|105.8| 192.7| 71.4|  55.7|\n",
      "|105.8| 192.7| 71.4|  55.9|\n",
      "| 99.5| 178.2| 67.9|  52.0|\n",
      "|101.2| 176.8| 64.8|  54.3|\n",
      "|101.2| 176.8| 64.8|  54.3|\n",
      "|101.2| 176.8| 64.8|  54.3|\n",
      "|101.2| 176.8| 64.8|  54.3|\n",
      "|103.5| 189.0| 66.9|  55.7|\n",
      "|103.5| 189.0| 66.9|  55.7|\n",
      "|103.5| 193.8| 67.9|  53.7|\n",
      "|110.0| 197.0| 70.9|  56.3|\n",
      "| 88.4| 141.1| 60.3|  53.2|\n",
      "| 94.5| 155.9| 63.6|  52.0|\n",
      "+-----+------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.22836801258821893,0.8223218915856468,0.580595102043434]\n",
      "Intercept: -26.380531957157498\n",
      "numIterations: 11\n",
      "objectiveHistory: [0.5, 0.38579526656819896, 0.13000842393266873, 0.12985504772567413, 0.12963704261349218, 0.12947103310674205, 0.1294164378448031, 0.1294050846483987, 0.12940508261516015, 0.1294050824628613, 0.12940508245526855]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  -4.611862798093398|\n",
      "|  -4.611862798093398|\n",
      "|  -2.501339043881387|\n",
      "|-0.11328232985025011|\n",
      "| -0.6777467081673763|\n",
      "|  0.3413419946315486|\n",
      "|  -2.878914311626758|\n",
      "|  -2.878914311626758|\n",
      "| -2.9950333320354474|\n",
      "| -0.8412496309870932|\n",
      "|  2.3922947158520174|\n",
      "|  2.3922947158520174|\n",
      "|  2.3922947158520174|\n",
      "|  2.3922947158520174|\n",
      "| -0.6335041529149237|\n",
      "| -0.6335041529149237|\n",
      "| -1.3908023008371515|\n",
      "|  0.4019071188106693|\n",
      "|   2.084135889634638|\n",
      "|   2.787341183548463|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 2.517190\n",
      "r2: 0.824407\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "assembler = VectorAssembler(inputCols=data.columns[1:], outputCol=\"features\")\n",
    "y = assembler.transform(data)\n",
    "\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "model = lr.fit(y)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "print(\"Intercept: %s\" % str(model.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = model.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "logistic_df = df.withColumn(\"label\", when(col(\"num-of-doors\") == \"four\", 1).otherwise(0)).select(\"label\", \"length\", \"width\", \"height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.000100509510875788]\n",
      "Intercept: 0.22531532410664368\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "assembler = VectorAssembler(inputCols=logistic_df.columns[1:], outputCol=\"features\")\n",
    "z = assembler.transform(logistic_df)\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "model = lr.fit(z)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial coefficients: DenseMatrix([[ 0.00000000e+00,  0.00000000e+00, -7.35292649e-05],\n",
      "             [ 0.00000000e+00,  0.00000000e+00,  7.35292649e-05]])\n",
      "Multinomial intercepts: [-0.11156262444620539,0.11156262444620539]\n"
     ]
    }
   ],
   "source": [
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlr_model = mlr.fit(z)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlr_model.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlr_model.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
